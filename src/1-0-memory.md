# 内存管理

> 程序 = 算法 + 数据结构 （或者更简单的版本：**程序 = 过程 + 数据**）

如今，用很多编程语言（如 Python）写程序时，我们并不需要关心我们所操作的数据在哪里、还在不在那。这些语言不仅保证在你还需要一份数据的时候，它能够随时被访问到，很多时候它们还做一些更为隐蔽的内存操作，让你不必考虑数据存放在内存中的何处、为它们最初的分配空间是否足够、多余的空间是否浪费，等等。

这些自动化的内存管理都无可争议地大大简化了编程的思维方式。但如同计算机科学中的每一个话题，在获得一项好处的同时，必然意味着对另一些的舍弃。很多时候这种取舍确实是值得的（这就是为什么 Python、Java 等语言总是在最受欢迎的语言列表中），但它并不是所有情况下的最佳选项。在讨论另一种的解决方案之前，我们首先了解一下大多数编程语言为了更简单的内存管理，都舍弃了些什么。

首先，为了提供一个更加简单的数据访问模型，一些额外的性能损失是无法避免的。这些损失包括维持访问模型的直接开销，如在 Java 中，程序不需要关心数据所占用的内存空间何时分配、何时释放，但 JVM 需要通过额外的垃圾回收机制保证数据的分配和释放；也包括无法实现最优的内存排布所导致的间接损失，这种损失既可能来自于程序员不了解内存排布对性能的影响而无意编写出的低效程序，也可能最优的方案由于语言限制根本就无法实现。如果应用本身对于性能并不敏感，这些损失我们可以不必在意，而不断发展的编译器优化技术也在缓解这两类性能损失。然而，在性能高度敏感的基础性应用中，这些额外损耗就变得不那么能接受了。

除了执行性能的损失外，为了提供简化的数据访问模型，语言的运行时（Runtime）也会变得更加庞大。每个程序语言的运行时需要构建起程序的抽象模型到实际机器的桥梁，程序抽象越远离机器，这座桥梁就需要越大。在有些语言中，这座桥梁所要承载的功能太过复杂，以至于语言提供了专门的解释器/虚拟机层来实现。这些语言的运行时往往十分庞大（如 Node.js 运行时超过 30MB，Java 运行时超过 100MB）。另一些语言（即编译型语言，如 C、C++、Go 等）通过实现运行时库函数（runtime library）来构建这类桥梁，更简化的模型也将不可避免地带来更大的库函数。同样，这个问题很多时候都不算是问题，但在系统编程中，即使这样的问题也值得锱铢必较。

除了额外的消耗，由于你不再直接操作内存，你事实上失去了对最底层机器的直接控制。底层控制不仅意味着你可以更加明确控制内存排布，更重要的是你更加能够预知程序的执行时间和行为。而失去了这种控制，也就意味着你的程序如何执行并不完全由你的代码如何编写决定。一个典型的例子是 stop-the-world 的全量垃圾回收，在这里回收的时间一般是由语言而不是程序决定的，这使得你并不能预知程序何时会出现中断或延迟（想象一下这在自动驾驶等应用中的影响）。

读到这里，也许你想：“这些问题我都不是很在意，这本书我不必看了。”你也许对于很多语言提供的解决方案比较满意，也愿意为此付出一些代价。但这种解决方案还是存在一个问题：往往你要付出的代价是隐性的、强制的。这有点像你去办电信业务，你总会想知道你的套餐包含哪些服务、分别要多少费用，你还应当能够随时退订你不需要的服务、从而不再为它们付钱。但不同语言提供的“服务”更像是一种不能更改的套餐，你也不能明确知道你在为什么付出代价。一旦将来有一天你觉得当前的代价过高，你很难知道到底是什么服务导致的，很多时候你甚至根本无法退订这些服务。

总结而言，当前的编程语言为了提供更简单的内存管理，削弱了程序的效率和控制力，也影响了你选择的权利，而这些都成为了 C / C++ 等底层系统语言仍然存在的关键理由。

习惯了高级程序语言的程序员，可能会觉得 C 语言的内存管理充满了陷阱。其中的原因也很好理解：真实的机器其实并不如抽象模型中的那样简洁，而 C 语言作为更加接近机器的底层语言，既不会替你考虑、也不会为你掩盖这些细枝末节，它把处理细节的自由度完全交给了程序员。这自然给了你最优的性能、最高的控制权等等，但同时，这些琐碎的细节也会让你变得更加容易出错，C 的自由同时也意味着危险。

C++ 通过为 C 语言增添不同的编程范式，似乎为这一问题提供了一个解决思路：提供给程序员更多的工具，程序员就可以通过很多手段从细枝末节中脱离出来。这里事实上蕴含了一个假定：程序越容易编写，就越不容易出错，然而这个假定本身中还有些疑点。首先，细节和复杂性是客观存在的，让编程更加“容易”，是意味着真正处理了复杂性还是只是在隐藏它们？其次，提供给程序员更多的工具似乎是能够让程序员拥有更强的能力，但使用这些工具的终究还是人，更多的工具会不会成为更多错误的源泉？我们能够观察到相当一部分 C++ 的程序员，的确不再关心底层细节，更多的工具也只让他们写出更加不可读也不可靠的代码，“精通 C++”也就成了一个程序员笑话。

编程是人类的行为，中间发生的错误的来源也正是人的局限性。复杂性是客观存在的，同时人类对于复杂性的处理能力是有限的。比起将复杂性和危险隐藏在不加约束的自由之下，更明确地暴露问题似乎才更有利于问题的解决。而真正解决复杂性的手段，在计算机科学的历史中也无数次被证明，不是期待人去解决更复杂的问题，而是依靠抽象的手段、让人只需要解决更简单的问题。而这正是 Rust 选择的解决方案。

下面我们将从 C 语言中隐藏的陷阱出发，看看 Rust 是如何通过明确问题和提供抽象，实现同样底层但更加安全内存管理。

<!-- 
程序员常常会问自己这样一个问题，如何提高我的程序的性能？有个有点偷懒但很有效的答案，就是寻找程序当前的**性能瓶颈**并优化它。那么更具体一点说，性能瓶颈一般在哪呢？第一有可能的瓶颈自然是算法，但第二可能便是内存控制了。

> 程序 = 算法 + 数据结构 （或者更简单的版本：**程序 = 过程 + 数据**）

对于程序而言，内存是操作系统提供的一种即时的、高效的数据存储的抽象，然而这种高效不是完美的：内存的访问速度终究有限，内存本身也并非无穷大，内存的分配、释放、移动等都需要一定的管理成本。为了应对这些问题，硬件和操作系统实现了多级缓存等机制，能够在很多情况下直接带来隐式的效率提升，但这仍不意味着程序可以以任意的方式使用内存。对于程序而言，若能够了解和规避内存的局限性、充分运用缓存等底层机制，仔细地规划内存的使用，程序的性能常常能够得到更深度的优化。

除了宽泛的性能问题之外，程序员希望对内存有更精细的控制的场合还有很多，比如对确定性或实时性有较高要求的场合，系统资源高度受限的场合，针对操作系统底层进行开发的场合等。但长久以来，系统程序员似乎面临着这样的困境：在现有的语言中，选择了更多更底层的控制，就意味着更容易出错；而选择了安全保障，则意味着更少控制。类似的抉择常常在是否要垃圾回收上体现：选择垃圾回收，你可以获得对内存访问的更多保障，如没有内存泄露问题，也没有悬垂指针、二次释放等广泛存在的内存安全问题，但你也因此无法直接触碰内存、控制内存的排布，无法决定（或者难以决定）何时回收垃圾，从而失去了一些优化的可能（编译器或虚拟机有时会帮你优化，你也可以通过编码技巧来促进这种优化，但终究比较间接和不可控）。

那么，底层控制和安全性真的无法同时保障吗？需要首先明确的是，越接近底层控制，程序员越需要对底层机制有深入的了解，面对的状况也越复杂，这个复杂性是无法规避的。但复杂性并不直接意味着失去安全性，仅仅是提供安全保障也不意味着必须削弱控制。也就是说底层控制和安全保障并不是直接冲突的。我们真正需要解决的是复杂性的问题。

泛泛而言，复杂性导致出错不外乎如下几个原因：

* 对复杂性理解不足；
* 繁琐的细节中出错；
* 疲于应付繁琐细节、导致整体逻辑出错。

解决问题也应该是对症下药，通过明确化来直面复杂性，和通过抽象来解决复杂性。

**直面复杂性**：复杂性越直接暴露，也就越能促使程序员深入了解背后发生了什么。系统编程最为复杂的部分便是内存控制。因而，本章节将介绍内存机制如何在 rust 中显式呈现、不同的内存操作对操作对象有何要求、以及 rust 所提供的不同层次的安全保障和所要付出代价之间的显式权衡，最后以并发编程为例，展示这种明确化的潜在力量。

**应对复杂性**：几乎每一本计算机科学的书都会谈到，应对复杂性最佳方式是抽象，而 rust 的抽象机制将在后续章节中介绍。 -->

<!--
参考：
https://doc.rust-lang.org/nomicon/index.html
https://docs.rust-embedded.org/book/static-guarantees/index.html
https://doc.rust-lang.org/1.5.0/book/choosing-your-guarantees.html
-->
