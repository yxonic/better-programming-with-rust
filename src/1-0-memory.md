# 内存管理

> 程序 = 算法 + 数据结构 （或者更简单的版本：**程序 = 过程 + 数据**）

如今，用很多编程语言（如 Python）写程序，很多时候我们并不需要关心我们所操作的数据在哪里，还在不在那。这些语言不仅保证在你还需要一份数据的时候，它能够随时被访问到，很多时候它们还做一些更为隐蔽的内存操作，让你不必考虑它们在内存中的何处、为它们最初的分配空间是否足够、多余的空间是否浪费，等等。

这些自动化的内存管理都无可争议地大大简化了编程的思维方式。但如同计算机科学中的每一个话题，在获得一项好处的同时，必然意味着对另一些的舍弃。很多时候这种取舍确实是值得的（这就是为什么 Python、Java 等语言总是在最受欢迎的语言列表中），但它并不是所有情况下的最佳选项。在讨论另一种的解决方案之前，我们首先了解一下大多数编程语言为了更简单的内存管理，都舍弃了些什么。

首先，为了提供一个更加简单的数据访问模型，一些额外的性能损失是无法避免的。这些损失包括维持访问模型的直接开销，如在 Java 中，程序不需要关心数据所占用的内存空间何时分配、何时释放，但 JVM 需要通过额外的垃圾回收机制保证数据的分配和释放；也包括无法实现最优的内存排布所导致的间接损失，这种损失既可能来自于程序员不了解内存排布对性能的影响而无意编写出的低效程序，也可能最优的方案由于语言限制根本就无法实现。如果应用本身对于性能并不敏感，这些损失我们可以不必在意，而不断发展的编译器优化技术也在缓解这两类性能损失。然而，在性能高度敏感的基础性应用中，这些额外损耗就变得不那么能接受了。

除了执行性能的损失外，为了提供简化的数据访问模型，语言的运行时（Runtime）也会变得更加庞大。每个程序语言的运行时需要构建起程序的抽象模型到实际机器的桥梁，程序抽象越远离机器，这座桥梁就需要越大。在有些语言中，这座桥梁所要承载的功能太过复杂，以至于语言提供了专门的解释器/虚拟机层来实现。这些语言的运行时往往十分庞大（如 Node.js 运行时超过 30MB，Java 运行时超过 100MB）。另一些语言（即编译型语言，如 C、C++、Go 等）通过实现运行时库函数（runtime library）来构建这类桥梁，更简化的模型也将不可避免地带来更大的库函数。同样，这个问题很多时候都不算是问题，但在系统编程中，即使这样的问题也值得锱铢必较。

【失去底层控制】

读到这里，也许你想：“这些问题我都不是很在意，这本书我不必看了。”你也许对于很多语言提供的抽象比较满意，也愿意付出一些代价。但这种模式还存在一个问题：往往你要付出的代价是隐性的、强制的。这有点像你去办电信业务，你总会想知道你的套餐包含哪些服务、分别要多少费用，你还应当能够随时退订你不需要的服务、从而不再为它们付钱。但不同语言提供的“服务”更像是一种不能更改的套餐，你也不能明确知道你在为什么付出代价。一旦将来有一天你觉得当前的代价过高，你很难知道到底是什么服务导致的，很多时候你甚至根本无法退订这些服务。

总结而言，当前的编程语言为了提供更简单的内存管理，削弱了程序的效率和控制力，也影响了你选择的权利，而这些都成为了 C / C++ 等底层系统语言仍然存在的关键理由。

习惯了高级程序语言的程序员，可能会觉得 C 语言的内存管理充满了陷阱。其中的原因也很好理解：真实的机器其实并不如抽象模型中的那样简洁，而 C 语言作为更加接近机器的底层语言，既不会替你考虑、也不会为你掩盖这些细枝末节。【问题：容易出错】

C++ 通过为 C 语言增添不同的编程范式，似乎为这一问题提供了一个解决思路：提供给程序员更多的工具，程序员就可以通过很多手段从细枝末节中脱离出来。这里似乎蕴含了一个假定：程序越容易编写，就越不容易出错，然而这个假定本身也有些偏颇。【1. 细节和复杂性终究存在，“容易”到底是处理了复杂性还是在掩盖复杂性？2. 使用工具的终究是人，更多的工具会不会成为更多错误的源泉？】

错误的真正来源是人对于复杂性难以处理。掩盖复杂性并不可取，把复杂性更加直接、更加明确地呈现出来似乎才是正确的道路。而真正处理复杂性的手段，在计算机科学的历史中也无数次被证明，不是期待人去解决更复杂的问题，而是依靠抽象的手段、让人能够解决更简单问题。

下面我们就从明确复杂性出发，看看 Rust 是如何将内存管理的细节通过语言本身呈现出来的。

<!-- 
程序员常常会问自己这样一个问题，如何提高我的程序的性能？有个有点偷懒但很有效的答案，就是寻找程序当前的**性能瓶颈**并优化它。那么更具体一点说，性能瓶颈一般在哪呢？第一有可能的瓶颈自然是算法，但第二可能便是内存控制了。

> 程序 = 算法 + 数据结构 （或者更简单的版本：**程序 = 过程 + 数据**）

对于程序而言，内存是操作系统提供的一种即时的、高效的数据存储的抽象，然而这种高效不是完美的：内存的访问速度终究有限，内存本身也并非无穷大，内存的分配、释放、移动等都需要一定的管理成本。为了应对这些问题，硬件和操作系统实现了多级缓存等机制，能够在很多情况下直接带来隐式的效率提升，但这仍不意味着程序可以以任意的方式使用内存。对于程序而言，若能够了解和规避内存的局限性、充分运用缓存等底层机制，仔细地规划内存的使用，程序的性能常常能够得到更深度的优化。

除了宽泛的性能问题之外，程序员希望对内存有更精细的控制的场合还有很多，比如对确定性或实时性有较高要求的场合，系统资源高度受限的场合，针对操作系统底层进行开发的场合等。但长久以来，系统程序员似乎面临着这样的困境：在现有的语言中，选择了更多更底层的控制，就意味着更容易出错；而选择了安全保障，则意味着更少控制。类似的抉择常常在是否要垃圾回收上体现：选择垃圾回收，你可以获得对内存访问的更多保障，如没有内存泄露问题，也没有悬垂指针、二次释放等广泛存在的内存安全问题，但你也因此无法直接触碰内存、控制内存的排布，无法决定（或者难以决定）何时回收垃圾，从而失去了一些优化的可能（编译器或虚拟机有时会帮你优化，你也可以通过编码技巧来促进这种优化，但终究比较间接和不可控）。

那么，底层控制和安全性真的无法同时保障吗？需要首先明确的是，越接近底层控制，程序员越需要对底层机制有深入的了解，面对的状况也越复杂，这个复杂性是无法规避的。但复杂性并不直接意味着失去安全性，仅仅是提供安全保障也不意味着必须削弱控制。也就是说底层控制和安全保障并不是直接冲突的。我们真正需要解决的是复杂性的问题。

泛泛而言，复杂性导致出错不外乎如下几个原因：

* 对复杂性理解不足；
* 繁琐的细节中出错；
* 疲于应付繁琐细节、导致整体逻辑出错。

解决问题也应该是对症下药，通过明确化来直面复杂性，和通过抽象来解决复杂性。

**直面复杂性**：复杂性越直接暴露，也就越能促使程序员深入了解背后发生了什么。系统编程最为复杂的部分便是内存控制。因而，本章节将介绍内存机制如何在 rust 中显式呈现、不同的内存操作对操作对象有何要求、以及 rust 所提供的不同层次的安全保障和所要付出代价之间的显式权衡，最后以并发编程为例，展示这种明确化的潜在力量。

**应对复杂性**：几乎每一本计算机科学的书都会谈到，应对复杂性最佳方式是抽象，而 rust 的抽象机制将在后续章节中介绍。 -->

<!--
参考：
https://doc.rust-lang.org/nomicon/index.html
https://docs.rust-embedded.org/book/static-guarantees/index.html
https://doc.rust-lang.org/1.5.0/book/choosing-your-guarantees.html
-->
